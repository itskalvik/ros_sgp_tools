{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405685a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- NO TYPE 3 FONTS IN PDF OUTPUT ---\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams[\"pdf.fonttype\"] = 42\n",
    "mpl.rcParams[\"ps.fonttype\"] = 42\n",
    "mpl.rcParams[\"font.family\"] = \"DejaVu Sans\"\n",
    "mpl.rcParams[\"mathtext.fontset\"] = \"dejavusans\"\n",
    "mpl.rcParams[\"text.usetex\"] = False\n",
    "\n",
    "# Font sizes\n",
    "mpl.rcParams[\"font.size\"] = 14\n",
    "mpl.rcParams[\"axes.titlesize\"] = 14\n",
    "mpl.rcParams[\"axes.labelsize\"] = 14\n",
    "mpl.rcParams[\"xtick.labelsize\"] = 14\n",
    "mpl.rcParams[\"ytick.labelsize\"] = 14\n",
    "mpl.rcParams[\"legend.fontsize\"] = 12\n",
    "# -------------------------------------\n",
    "\n",
    "import os\n",
    "import h5py\n",
    "import yaml\n",
    "import pickle\n",
    "import shapely\n",
    "import numpy as np\n",
    "from utils import LatLonStandardScaler, StandardScaler\n",
    "\n",
    "from sgptools.kernels import *\n",
    "from sgptools.utils.gpflow import *\n",
    "from sgptools.utils.metrics import *\n",
    "from sgptools.utils.misc import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8885b760",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cont2disc(\n",
    "    Xu: np.ndarray,\n",
    "    candidates: np.ndarray,\n",
    "    candidate_labels: Optional[np.ndarray] = None\n",
    ") -> Union[np.ndarray, Tuple[np.ndarray, np.ndarray]]:\n",
    "    \"\"\"\n",
    "    Maps continuous space locations (`Xu`) to the closest points in a discrete\n",
    "    set of candidate locations (`candidates`) using a Hungarian algorithm\n",
    "    (linear sum assignment) for optimal matching. This ensures each `Xu` point\n",
    "    is matched to a unique candidate.\n",
    "\n",
    "    Args:\n",
    "        Xu (np.ndarray): (m, d); Continuous space points (e.g., optimized sensor locations).\n",
    "                         `m` is the number of points, `d` is the dimensionality.\n",
    "        candidates (np.ndarray): (n, d); Discrete set of candidate locations.\n",
    "                                 `n` is the number of candidates, `d` is the dimensionality.\n",
    "        candidate_labels (Optional[np.ndarray]): (n, 1); Optional labels corresponding to\n",
    "                                                the discrete set of candidate locations.\n",
    "                                                If provided, the matched labels are also returned.\n",
    "                                                Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        Union[np.ndarray, Tuple[np.ndarray, np.ndarray]]:\n",
    "        - If `candidate_labels` is None:\n",
    "            np.ndarray: (m, d); Discrete space points' locations (`Xu_X`),\n",
    "                        where each point in `Xu` is mapped to its closest\n",
    "                        unique point in `candidates`.\n",
    "        - If `candidate_labels` is provided:\n",
    "            Tuple[np.ndarray, np.ndarray]: (`Xu_X`, `Xu_y`).\n",
    "            `Xu_X` (np.ndarray): (m, d); The matched discrete locations.\n",
    "            `Xu_y` (np.ndarray): (m, 1); The labels corresponding to `Xu_X`.\n",
    "\n",
    "    Usage:\n",
    "        ```python\n",
    "        import numpy as np\n",
    "        from sgptools.utils.misc import cont2disc\n",
    "\n",
    "        # Example continuous points\n",
    "        continuous_points = np.array([[0.1, 0.1], [0.9, 0.9], [0.5, 0.5]])\n",
    "        # Example discrete candidates\n",
    "        discrete_candidates = np.array([[0.0, 0.0], [1.0, 1.0], [0.4, 0.6]])\n",
    "        # Example candidate labels (optional)\n",
    "        discrete_labels = np.array([[10.0], [20.0], [15.0]])\n",
    "\n",
    "        # 1. Map without labels\n",
    "        mapped_points = cont2disc(continuous_points, discrete_candidates)\n",
    "\n",
    "        # 2. Map with labels\n",
    "        mapped_points_X, mapped_points_y = cont2disc(continuous_points, discrete_candidates, discrete_labels)\n",
    "        ```\n",
    "    \"\"\"\n",
    "    # Sanity check to handle empty inputs gracefully\n",
    "    if len(candidates) == 0 or len(Xu) == 0:\n",
    "        if candidate_labels is not None:\n",
    "            return np.empty((0, Xu.shape[1])), np.empty((0, 1))\n",
    "        else:\n",
    "            return np.empty((0, Xu.shape[1]))\n",
    "        \n",
    "    # Compute pairwise Euclidean distances between candidates and Xu\n",
    "    dists = pairwise_distances(candidates, Y=Xu, metric='euclidean')\n",
    "\n",
    "    # Use the Hungarian algorithm (linear_sum_assignment) to find the optimal\n",
    "    # assignment of rows (candidates) to columns (Xu points) that minimizes\n",
    "    # the total cost (distances). `row_ind` gives the indices of the rows\n",
    "    # (candidates) chosen, `col_ind` gives the corresponding indices of `Xu`.\n",
    "    row_ind, col_ind = linear_sum_assignment(dists)\n",
    "\n",
    "    # Select the candidate locations that were matched to Xu points\n",
    "    Xu_X = candidates[row_ind].copy()\n",
    "\n",
    "    if candidate_labels is not None:\n",
    "        # If labels are provided, select the corresponding labels as well\n",
    "        Xu_y = candidate_labels[row_ind].copy()\n",
    "        return Xu_X, Xu_y, row_ind\n",
    "    else:\n",
    "        return Xu_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faccf845",
   "metadata": {},
   "outputs": [],
   "source": [
    "mission_log = \"../launch/data/auv\"\n",
    "num_samples = 5000\n",
    "controller = \"aqua2\"\n",
    "\n",
    "# data file\n",
    "fname = os.path.join(mission_log,\n",
    "                     \"mission-log.hdf5\")\n",
    "\n",
    "# load data\n",
    "with h5py.File(fname, \"r\") as f:\n",
    "    print(f.keys())\n",
    "    fence_vertices = f[\"fence_vertices\"][:].astype(float)\n",
    "    X = f[\"X\"][:].astype(float)\n",
    "    y = f[\"y\"][:].astype(float)\n",
    "\n",
    "    X_candidates = f[\"X_objective\"][:].astype(float)\n",
    "\n",
    "    X_init = f[\"X_init\"][:].astype(float)\n",
    "    y_init = f[\"y_init\"][:].astype(float)\n",
    "\n",
    "    for key in f.keys():\n",
    "        if 'initial' in key:\n",
    "            initial_path = f[key][:].astype(float)\n",
    "        elif 'coverage' in key:\n",
    "            sol_path = f[key][:].astype(float)\n",
    "\n",
    "print(f'Mission Log: {mission_log}')\n",
    "print(f'Number of initial data samples: {X_init.shape[0]}')\n",
    "print(f'Number of solution data samples: {X.shape[0]}')\n",
    "print(f'Number of reconstruction samples: {num_samples}')\n",
    "\n",
    "if controller == 'mavros':\n",
    "    X_scaler = LatLonStandardScaler()\n",
    "    X_scaler.fit(X_candidates)\n",
    "elif controller == 'aqua2':\n",
    "    X_scaler = StandardScaler()\n",
    "    X_scaler.fit(X_candidates)\n",
    "\n",
    "    # Change variance/scale parameter to ensure all axis are scaled to the same value\n",
    "    ind = np.argmax(X_scaler.var_)\n",
    "    X_scaler.var_ = np.ones(X.shape[-1])*X_scaler.var_[ind]\n",
    "    X_scaler.scale_ = np.ones(X.shape[-1])*X_scaler.scale_[ind]\n",
    "    X_scaler.scale_ /= 10.0  # Scale to ensure an extent of ~10 units\n",
    "\n",
    "# Transform data\n",
    "X_candidates = X_scaler.transform(X_candidates)\n",
    "y_scaler = StandardScaler()\n",
    "y_scaler.fit(y)\n",
    "\n",
    "y = y_scaler.transform(y)\n",
    "X = X_scaler.transform(X)\n",
    "\n",
    "y_init = y_scaler.transform(y_init)\n",
    "X_init = X_scaler.transform(X_init)\n",
    "\n",
    "initial_path = X_scaler.transform(initial_path)\n",
    "sol_path = X_scaler.transform(sol_path)\n",
    "\n",
    "fence_vertices = X_scaler.transform(fence_vertices)\n",
    "sol_X, sol_y, ind = cont2disc(sol_path, X, y)\n",
    "\n",
    "# Load aqua data\n",
    "if controller == 'aqua2':\n",
    "    fname = os.path.join(mission_log, \"15-49.npy\")\n",
    "    data = np.load(fname)[280:2140]\n",
    "    X_data = data[:, :2]\n",
    "    y_data = data[:, 2].reshape(-1, 1)\n",
    "    X_data_all = X_scaler.transform(X_data)\n",
    "    y_data_all = y_scaler.transform(y_data)\n",
    "    X_data, y_data, ind_data = cont2disc(sol_path, X_data_all, y_data_all)\n",
    "elif controller == 'mavros':\n",
    "    X_data_all = X\n",
    "    y_data_all = y\n",
    "    X_data, y_data, ind_data = cont2disc(sol_path, X_data_all, y_data_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bccd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute grid\n",
    "distance = 0.3\n",
    "len_x = max(X_candidates[:, 0])-min(X_candidates[:, 0])\n",
    "len_y = max(X_candidates[:, 1])-min(X_candidates[:, 1])\n",
    "num_x = int(np.ceil(len_x/distance))\n",
    "num_y = int(np.ceil(len_y/distance))\n",
    "extent = [min(X_candidates[:, 0]), max(X_candidates[:, 0]), \n",
    "          min(X_candidates[:, 1]), max(X_candidates[:, 1])]\n",
    "grid_x, grid_y = np.mgrid[extent[0]:extent[1]:complex(num_x), \n",
    "                          extent[2]:extent[3]:complex(num_y)]\n",
    "X_grid = np.stack([grid_x, grid_y], axis=-1)\n",
    "X_grid = X_grid.reshape(-1, 2).astype(X_candidates.dtype)\n",
    "\n",
    "print(num_x, num_y)\n",
    "\n",
    "# Remove sensing locations outside the boundaries\n",
    "pbounds = shapely.geometry.Polygon(fence_vertices)\n",
    "points = shapely.points(X_grid)\n",
    "inside_idx = shapely.contains(pbounds, points)\n",
    "outside_idx = np.logical_not(inside_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201ac400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract hyperparameters details from config.yaml\n",
    "config_fname = os.path.join(mission_log, f\"config.yaml\")\n",
    "with open(config_fname, 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "hyperparameter_config = config.get('hyperparameters', {})\n",
    "kernel = hyperparameter_config.get('kernel_function', 'RBF')\n",
    "\n",
    "# Use float32 and higher jitter for deep learning model based kernel functions\n",
    "if kernel in ['Attentive', 'NeuralSpectral']:\n",
    "    gpflow.config.set_default_float(np.float32)\n",
    "    gpflow.config.set_default_jitter(1e-1)\n",
    "else:\n",
    "    gpflow.config.set_default_float(np.float64)\n",
    "    gpflow.config.set_default_jitter(1e-6)\n",
    "\n",
    "kernel_kwargs = hyperparameter_config.get('kernel', {})\n",
    "kernel = get_kernel(kernel)(**kernel_kwargs)\n",
    "noise_variance = float(hyperparameter_config.get('noise_variance', 1e-4))\n",
    "optimizer_kwargs = config.get('optimizer', {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2991201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init GP model\n",
    "_, _, _, gpr = get_model_params(np.vstack([X_init]).astype(np.float32), \n",
    "                                np.vstack([y_init]).astype(np.float32), \n",
    "                                kernel=kernel,\n",
    "                                noise_variance=noise_variance,\n",
    "                                return_model=True,\n",
    "                                force_gp=True,\n",
    "                                verbose=False,\n",
    "                                max_steps=0)\n",
    "\n",
    "# Load pre-trained parameters\n",
    "fname = os.path.join(mission_log, f\"model_params.pkl\")\n",
    "with open(fname, 'rb') as handle:\n",
    "    params = pickle.load(handle)\n",
    "gpflow.utilities.multiple_assign(gpr.kernel, params['kernel'])\n",
    "gpflow.utilities.multiple_assign(gpr.likelihood, params['likelihood'])\n",
    "\n",
    "mean, var_prior = gpr.predict_f(X_candidates.astype(np.float32))\n",
    "print(\"Max Variance:\", var_prior.numpy().max())\n",
    "\n",
    "# ---- Plot lengthscale map ----\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "lengthscales = kernel.get_lengthscales(X_grid.astype(np.float32))\n",
    "lengthscales[outside_idx] = np.nan\n",
    "\n",
    "im = ax.imshow(\n",
    "    lengthscales.reshape(num_x, num_y).T,\n",
    "    origin='lower',\n",
    "    extent=extent,\n",
    "    cmap='plasma'\n",
    ")\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"4%\", pad=0.08)  # tweak size/pad as desired\n",
    "fig.colorbar(im, cax=cax)\n",
    "\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_title('Lengthscale Predictions\\n')\n",
    "fig.savefig(\"lengthscales\", bbox_inches=\"tight\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ---- Plot variance map (prior) ----\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "_, var = gpr.predict_f(X_grid.astype(np.float32))\n",
    "var = var.numpy()\n",
    "var_min = var.min()\n",
    "var_max = var.max()\n",
    "\n",
    "var[outside_idx] = np.nan\n",
    "\n",
    "im = ax.imshow(\n",
    "    var.reshape(num_x, num_y).T,\n",
    "    origin='lower',\n",
    "    extent=extent,\n",
    "    vmin=var_min, \n",
    "    vmax=var_max,\n",
    "    cmap='plasma'\n",
    ")\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"4%\", pad=0.08)  # tweak size/pad as desired\n",
    "fig.colorbar(im, cax=cax)\n",
    "\n",
    "if controller == 'mavros':\n",
    "    ax.plot(initial_path[:, 0], initial_path[:, 1], c='C2', marker='o', markersize=5, label='Planned Path')\n",
    "    ax.scatter(X_init[:, 0], X_init[:, 1], c='r', s=5, label='ASV Path/Collected Data', zorder=10, alpha=0.4)\n",
    "\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.legend(loc='lower left')\n",
    "ax.set_title(f'Prior Prediction Variance\\nMax Var: {var_prior.numpy().max():.2f}')\n",
    "fig.savefig(\"prior\", bbox_inches=\"tight\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9fd700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init GP model\n",
    "_, _, _, gpr_post = get_model_params(np.vstack([X_init, X_data]).astype(np.float32), \n",
    "                                     np.vstack([y_init, y_data]).astype(np.float32), \n",
    "                                     kernel=kernel,\n",
    "                                     noise_variance=noise_variance,\n",
    "                                     return_model=True,\n",
    "                                     force_gp=True,\n",
    "                                     verbose=False,\n",
    "                                     max_steps=0)\n",
    "\n",
    "# Load pre-trained parameters\n",
    "fname = os.path.join(mission_log, f\"model_params.pkl\")\n",
    "with open(fname, 'rb') as handle:\n",
    "    params = pickle.load(handle)\n",
    "gpflow.utilities.multiple_assign(gpr_post.kernel, params['kernel'])\n",
    "gpflow.utilities.multiple_assign(gpr_post.likelihood, params['likelihood'])\n",
    "\n",
    "_, var_post = gpr_post.predict_f(X_candidates.astype(np.float32))\n",
    "print(\"Max Variance:\", var_post.numpy().max())\n",
    "\n",
    "# ---- Plot variance map (posterior) ----\n",
    "\n",
    "mean, var = gpr_post.predict_f(X_grid.astype(np.float32))\n",
    "mean = mean.numpy()\n",
    "var = var.numpy()\n",
    "var[outside_idx] = np.nan\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "im = ax.imshow(\n",
    "    var.reshape(num_x, num_y).T,\n",
    "    origin='lower',\n",
    "    extent=extent,\n",
    "    vmin=var_min, \n",
    "    vmax=var_max,\n",
    "    cmap='plasma'\n",
    ")\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"4%\", pad=0.08)  # thickness + spacing\n",
    "fig.colorbar(im, cax=cax)\n",
    "\n",
    "ax.plot(sol_path[:, 0], sol_path[:, 1], c='C2', marker='o', markersize=5, label='Planned Path')\n",
    "ax.plot(X_data_all[:, 0], X_data_all[:, 1], c='r', markersize=5, label='ASV Path', zorder=10, alpha=1)\n",
    "ax.scatter(X_data[:, 0], X_data[:, 1], c='r', s=25, label='Collected Data', zorder=10)\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.legend(loc='lower left')\n",
    "ax.set_title(f'Posterior Prediction Variance\\nTarget Var: {var_prior.numpy().max()*0.5:.2f}; Max Var: {var_post.numpy().max():.2f}')\n",
    "fig.savefig(\"posterior\", bbox_inches=\"tight\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97aa1541",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "import imageio.v2 as imageio\n",
    "from tqdm import trange\n",
    "\n",
    "# ----------------------------\n",
    "# CONFIG\n",
    "# ----------------------------\n",
    "fps = 12\n",
    "out_mp4 = f\"{controller}.mp4\"\n",
    "\n",
    "FIGSIZE = (7.2, 6.0)   # fixed canvas size\n",
    "DPI = 150              # fixed DPI\n",
    "\n",
    "X_grid_f32 = X_grid.astype(np.float32)\n",
    "\n",
    "X_data_all = np.asarray(X_data_all)\n",
    "ind_end = np.asarray(ind_data, dtype=int)\n",
    "\n",
    "T = len(X_data_all)\n",
    "n_wp = len(X_data)\n",
    "\n",
    "# Clamp safely\n",
    "ind_end = np.clip(ind_end, 0, T - 1)\n",
    "\n",
    "# ----------------------------\n",
    "# GP UPDATE HELPERS\n",
    "# ----------------------------\n",
    "def update_gp_to_k_waypoints(k: int):\n",
    "    \"\"\"Update GP training data using waypoint/data up to k (k in [0..n_wp]).\"\"\"\n",
    "    if k <= 0:\n",
    "        X_train = np.asarray(X_init, dtype=np.float32)\n",
    "        y_train = np.asarray(y_init, dtype=np.float32)\n",
    "    else:\n",
    "        X_train = np.vstack([X_init, X_data[:k]]).astype(np.float32)\n",
    "        y_train = np.vstack([y_init, y_data[:k]]).astype(np.float32)\n",
    "\n",
    "    gpr_post.data = (X_train, y_train)\n",
    "\n",
    "def compute_variance_grid_flat():\n",
    "    \"\"\"Variance on grid as flat array with outside masked to NaN.\"\"\"\n",
    "    _, var = gpr_post.predict_f(X_grid_f32)\n",
    "    _, var_post = gpr_post.predict_f(X_candidates.astype(np.float32))\n",
    "    var = var.numpy().reshape(-1)\n",
    "    var[outside_idx] = np.nan\n",
    "    return var, var_post.numpy().mean(), var_post.numpy().max()\n",
    "\n",
    "# ----------------------------\n",
    "# INITIALIZE GP (k=0)\n",
    "# ----------------------------\n",
    "last_k = 0\n",
    "update_gp_to_k_waypoints(last_k)\n",
    "var_flat, var_post_mean, var_post_max = compute_variance_grid_flat()\n",
    "\n",
    "# ----------------------------\n",
    "# RENDER + ENCODE (NO FILE I/O)\n",
    "# ----------------------------\n",
    "with imageio.get_writer(out_mp4, fps=fps, codec=\"libx264\", quality=8, format=\"FFMPEG\") as writer:\n",
    "    for t in trange(T, desc=\"Rendering+encoding (dense ASV timesteps)\"):\n",
    "        k = int(np.searchsorted(ind_end, t, side=\"right\"))  # 0..n_wp\n",
    "\n",
    "        # Update GP only when a new waypoint is reached\n",
    "        if k != last_k:\n",
    "            update_gp_to_k_waypoints(k)\n",
    "            var_flat, var_post_mean, var_post_max = compute_variance_grid_flat()\n",
    "            last_k = k\n",
    "\n",
    "        asv_path = X_data_all[:t + 1]\n",
    "        asv_current = X_data_all[t]\n",
    "\n",
    "        # ---- Plot (fixed canvas size; no tight bbox) ----\n",
    "        fig, ax = plt.subplots(figsize=FIGSIZE, dpi=DPI)\n",
    "\n",
    "        im = ax.imshow(\n",
    "            var_flat.reshape(num_x, num_y).T,\n",
    "            origin=\"lower\",\n",
    "            extent=extent,\n",
    "            vmin=var_min,\n",
    "            vmax=var_max,\n",
    "            cmap=\"plasma\",\n",
    "        )\n",
    "        ax.set_aspect(\"equal\")\n",
    "\n",
    "        divider = make_axes_locatable(ax)\n",
    "        cax = divider.append_axes(\"right\", size=\"4%\", pad=0.08)\n",
    "        fig.colorbar(im, cax=cax)\n",
    "\n",
    "        ax.plot(sol_path[:, 0], sol_path[:, 1],\n",
    "                c=\"C2\", marker=\"o\", markersize=5, label=\"Planned Path\")\n",
    "        ax.plot(asv_path[:, 0], asv_path[:, 1],\n",
    "                c=\"r\", markersize=5, alpha=0.95, zorder=9, label=\"ASV Path\")\n",
    "        if k > 0:\n",
    "            ax.scatter(X_data[:k, 0], X_data[:k, 1],\n",
    "                       c=\"r\", s=25,\n",
    "                       zorder=13, label='Collected Data')\n",
    "        ax.scatter(asv_current[0], asv_current[1],\n",
    "                   s=55, c=\"white\", edgecolor=\"black\", linewidth=1.2,\n",
    "                   zorder=12, label=\"Current ASV Location\")\n",
    "\n",
    "        ax.set_xlabel(\"X\")\n",
    "        ax.set_ylabel(\"Y\")\n",
    "\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        seen = set()\n",
    "        uniq_h, uniq_l = [], []\n",
    "        for h, lab in zip(handles, labels):\n",
    "            if lab not in seen:\n",
    "                uniq_h.append(h)\n",
    "                uniq_l.append(lab)\n",
    "                seen.add(lab)\n",
    "        ax.legend(uniq_h, uniq_l, loc=\"lower left\")\n",
    "\n",
    "        ax.set_title(f'Posterior Prediction Variance\\nTarget Var: {var_prior.numpy().max()*0.5:.2f}; Max Var: {var_post_max:.2f}; Mean Var: {var_post_mean:.2f}')\n",
    "\n",
    "        fig.canvas.draw()\n",
    "        rgba = np.asarray(fig.canvas.buffer_rgba())   # (H, W, 4)\n",
    "        frame = rgba[..., :3].copy()                  # (H, W, 3)\n",
    "        writer.append_data(frame)\n",
    "\n",
    "        plt.close(fig)\n",
    "\n",
    "print(f\"Saved video: {out_mp4}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
